{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Lab: Let's Build a Multi-Agent AI Startup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™1.Lab Introduction\n",
    "\n",
    "Welcome to the **AutoGen Learning Lab**! In this lab, you'll simulate building a next-generation AI application using the **AutoGen framework** from Microsoft.\n",
    "\n",
    "Our use case is building an startup team using AI Agents. By the end, you'll not only familiar with AutoGen framework, but also **build a full AI Startup Team with multiple agents** that can work together to solve a complex task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 2. AutoGen Framework\n",
    "\n",
    "### 2.1 What is AutoGen Framework?\n",
    "\n",
    "**AutoGen** is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks. AutoGen aims to provide an easy-to-use and flexible framework for accelerating development and research on agentic AI.\n",
    "\n",
    "### 2.2 Why Use AutoGen?\n",
    "\n",
    "The AutoGen offers a complete toolkit for designing, implementing, and managing AI agent systems, with a special emphasis on multi-agent collaboration. It abstracts away the complexity of prompt engineering, role-based coordination, and long-context memory management, allowing developers to focus on high-level workflows.\n",
    "\n",
    "Key Reasons to Use AutoGen:\n",
    "\n",
    "- Multi-Agent Collaboration: AutoGen allows you to create applications where multiple AI agents, each with specialized roles, can communicate and cooperate to solve complex tasks-much like a human team. This is ideal for scenarios such as customer service bots, data analysis, content generation, and more.\n",
    "\n",
    "- Simplifies Complex Workflows: It streamlines the orchestration, automation, and optimization of intricate LLM workflows, making it easier to build, manage, and scale applications that would otherwise require significant engineering effort.\n",
    "\n",
    "- Customizable and Flexible: Developers can easily define agents with specific skills and behaviors, customize conversation patterns, and integrate human feedback when needed. This flexibility enables a wide range of use cases and allows for both autonomous and human-in-the-loop workflows.\n",
    "\n",
    "- Efficient Code Execution: AutoGen supports automated code execution in secure, containerized environments, enabling agents to write, test, and debug code collaboratively and autonomously-speeding up development and reducing manual intervention.\n",
    "\n",
    "- Reduces Errors and Increases Consistency: By automating repetitive tasks and providing robust coordination between agents, AutoGen helps reduce human error and ensures consistent results across projects.\n",
    "\n",
    "- Open Source and Actively Developed: Backed by Microsoft and an active research community, AutoGen is open source, well-documented, and continuously improved, making it accessible and reliable for developers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö 3. Key Concepts Deep Dive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LLM Config\n",
    "\n",
    "In AutoGen, llm_config is a dictionary that defines how an agent interacts with a large language model (LLM) such as GPT-4o. It controls the agent‚Äôs model behavior, including:\n",
    "\n",
    "- Which model to use (e.g., OpenAI GPT-4, Azure OpenAI Model)\n",
    "- Endpoint settings and API configuration\n",
    "- Model generation style (e.g., creative vs deterministic)\n",
    "- Tool usage (e.g., code execution tools)\n",
    "\n",
    "It acts as a bridge between the agent and the LLM backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the configuration for Azure OpenAI from .env file.\n",
    "# This includes the API key, endpoint, and other Azure-specific settings\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "        \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        \"base_url\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        \"api_type\": \"azure\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": config_list,  # Use the Azure OpenAI configuration\n",
    "    \"seed\": 42,  # Set a seed for caching and reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Base Agent Creation\n",
    "\n",
    "Agents are the fundamental units of intelligence in AutoGen. Each agent is:\n",
    "\n",
    "- Configurable: Can be given different roles, prompts, memory, and toolsets.\n",
    "- Conversational: Can send and receive structured messages.\n",
    "- Autonomous: Makes decisions based on incoming messages and internal logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import UserProxyAgent, AssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a User Proxy agent that represents the user\n",
    "user = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",  # Allow human input before termination\n",
    "    code_execution_config={\n",
    "        \"use_docker\": False,  # Don't use Docker for code execution\n",
    "    },\n",
    "    system_message=\"You are a user to provide requirements for the assistant, when you get the assistant's response, you can provide your own opinion and ask the assistant to improve the idea.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a assistant agent that will help with tasks\n",
    "assistant = AssistantAgent(name=\"Assistant\", llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Orchestration\n",
    "\n",
    "Orchestration is the art of coordinating multiple agents to solve a larger problem.\n",
    "\n",
    "This is achieved via:\n",
    "\n",
    "üß© GroupChat\n",
    "\n",
    "- Stores all agent interactions and messages\n",
    "- Ensures shared memory and message visibility\n",
    "\n",
    "üß† GroupChatManager\n",
    "\n",
    "- Selects which agent responds next\n",
    "- Controls round limits\n",
    "- Optional methods for speaker logic, stop conditions, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import GroupChat, GroupChatManager\n",
    "\n",
    "group = GroupChat(\n",
    "    agents=[user, assistant],\n",
    "    messages=[],\n",
    "    max_round=5,\n",
    "    speaker_selection_method=\"round_robin\",\n",
    ")\n",
    "manager = GroupChatManager(groupchat=group, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Entry Point\n",
    "\n",
    "The entry point for agentic orchestration, where the UserProxyAgent initiates a multi-agent interaction by injecting a task prompt into the GroupChatManager.\n",
    "\n",
    "It effectively defines the primary objective or problem statement around which all subsequent agent behaviors‚Äîplanning, reasoning, collaboration, and tool use‚Äîwill evolve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = \"Please propose a new AI product idea\"\n",
    "\n",
    "user.initiate_chat(\n",
    "    manager,\n",
    "    message=task_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° 4. Put Everything Together - Building a Multi-Agent AI Startup\n",
    "\n",
    "We will simulate a collaborative AI startup team composed of multiple specialized agents, each responsible for a distinct role in the product development lifecycle. These agents will work together to brainstorm ideas, define the vision, architect the solution, design the interface, implement the application, and provide critical feedback ‚Äî just like a real-world startup.\n",
    "\n",
    "üë• Agents Overview\n",
    "\n",
    "- Founder: Initiates the task and triggers the multi-agent workflow.\n",
    "\n",
    "- Product Manager (PM): Defines the product vision, user needs, and overall feature roadmap.\n",
    "\n",
    "- Tech Lead: Translates the product idea into a technical plan, outlining system components and technology stack.\n",
    "\n",
    "- UI/UX Designer: Designs the user experience by describing the layout, wireframes, and interaction flow.\n",
    "\n",
    "- Frontend Developer: Implements the UI using technologies like React and Tailwind CSS.\n",
    "\n",
    "- Backend Developer: Develops server-side logic, APIs, and integration with AI services.\n",
    "\n",
    "- Quality Assurance (QA): Performs quality assurance by reviewing the outputs of other agents‚Äîincluding code, design, and architecture‚Äîand provides constructive feedback to improve functionality, reliability, and usability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Import libraries and setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from autogen import UserProxyAgent, AssistantAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging to see execution messages\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define configuration loading function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load Azure OpenAI configuration from environment variables.\"\"\"\n",
    "    # List all required environment variables\n",
    "    required_vars = [\n",
    "        \"AZURE_OPENAI_MODEL\",  # The model name (e.g., gpt-4)\n",
    "        \"AZURE_OPENAI_API_KEY\",  # Your Azure OpenAI API key\n",
    "        \"AZURE_OPENAI_ENDPOINT\",  # Your Azure OpenAI endpoint URL\n",
    "        \"AZURE_OPENAI_API_VERSION\",  # API version to use\n",
    "    ]\n",
    "\n",
    "    # Check if any variables are missing\n",
    "    missing = [v for v in required_vars if not os.getenv(v)]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing required environment variables: {', '.join(missing)}\"\n",
    "        )\n",
    "\n",
    "    # Return configuration for Azure OpenAI\n",
    "    return [\n",
    "        {\n",
    "            \"model\": os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "            \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            \"base_url\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            \"api_type\": \"azure\",\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Define function to create all agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agents(config_list: List[Dict[str, Any]]) -> List[Any]:\n",
    "    \"\"\"Create all agents for the AI startup team.\"\"\"\n",
    "    # Create the Founder agent (User Proxy)\n",
    "    founder = UserProxyAgent(\n",
    "        name=\"Founder\",\n",
    "        human_input_mode=\"TERMINATE\",  # Allows termination with TERMINATE\n",
    "        max_consecutive_auto_reply=10,  # Maximum auto-replies before human input\n",
    "        is_termination_msg=lambda msg: msg.get(\"content\", \"\")\n",
    "        .strip()\n",
    "        .endswith(\"TERMINATE\"),  # Function to detect termination messages\n",
    "        code_execution_config={\n",
    "            \"work_dir\": \"output\",  # Directory for code execution outputs\n",
    "            \"use_docker\": False,  # Don't use Docker for code execution\n",
    "        },\n",
    "        system_message=\"You are the Founder of the AI startup. You initiate tasks and trigger the multi-agent workflow. Reply TERMINATE when done to end the conversation.\",\n",
    "    )\n",
    "\n",
    "    # Create Product Manager agent\n",
    "    product_manager = AssistantAgent(\n",
    "        name=\"ProductManager\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.3,  # Slightly creative but mostly focused\n",
    "            \"max_tokens\": 512,  # Maximum response length\n",
    "        },\n",
    "        system_message=\"\"\"You are the Product Manager. Your role is to define the product vision, user needs, and overall feature roadmap.\n",
    "        You translate customer problems into product requirements. Focus on:\n",
    "        1. Target user identification\n",
    "        2. User requirements and pain points\n",
    "        3. Feature prioritization\n",
    "        4. Product success metrics\n",
    "        5. Market positioning\n",
    "        Be specific and provide actionable insights that the technical team can implement.\"\"\",\n",
    "    )\n",
    "\n",
    "    # Create Tech Lead agent\n",
    "    tech_lead = AssistantAgent(\n",
    "        name=\"TechLead\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.2,  # More deterministic for technical decisions\n",
    "            \"max_tokens\": 512,\n",
    "        },\n",
    "        system_message=\"\"\"You are the Tech Lead. Your role is to translate the product idea into a technical plan.\n",
    "        You outline system components and technology stack. Focus on:\n",
    "        1. System architecture\n",
    "        2. Technology selection\n",
    "        3. Technical constraints and solutions\n",
    "        4. Implementation strategy\n",
    "        5. Scalability and performance considerations\n",
    "        Provide specific technical recommendations that balance innovation with practicality.\"\"\",\n",
    "    )\n",
    "\n",
    "    # Create UI/UX Designer agent\n",
    "    ui_ux_designer = AssistantAgent(\n",
    "        name=\"UI_UX_Designer\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.3,  # Slightly creative for design ideas\n",
    "            \"max_tokens\": 512,\n",
    "        },\n",
    "        system_message=\"\"\"You are the UI/UX Designer. Your role is to design the user experience.\n",
    "        You describe layouts, wireframes, and interaction flow. Focus on:\n",
    "        1. User journey mapping\n",
    "        2. Interface layout suggestions\n",
    "        3. Visual design principles\n",
    "        4. Interaction patterns\n",
    "        5. Accessibility considerations\n",
    "        Provide concrete design suggestions that create intuitive and engaging user experiences.\"\"\",\n",
    "    )\n",
    "\n",
    "    # Create Frontend Developer agent\n",
    "    frontend_developer = AssistantAgent(\n",
    "        name=\"FrontendDeveloper\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.2,  # More deterministic for coding\n",
    "            \"max_tokens\": 512,\n",
    "        },\n",
    "        system_message=\"\"\"You are the Frontend Developer. Your role is to implement the UI.\n",
    "        You specialize in technologies like React and Tailwind CSS. Focus on:\n",
    "        1. Component architecture\n",
    "        2. State management\n",
    "        3. Responsive design implementation\n",
    "        4. Frontend performance optimization\n",
    "        5. Frontend testing strategies\n",
    "        Provide specific implementation approaches for building robust frontend solutions.\"\"\",\n",
    "    )\n",
    "\n",
    "    # Create Backend Developer agent\n",
    "    backend_developer = AssistantAgent(\n",
    "        name=\"BackendDeveloper\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.2,  # More deterministic for backend logic\n",
    "            \"max_tokens\": 512,\n",
    "        },\n",
    "        system_message=\"\"\"You are the Backend Developer. Your role is to develop server-side logic, APIs, and integration with AI services.\n",
    "        Focus on:\n",
    "        1. API design and implementation\n",
    "        2. Database schema\n",
    "        3. Server architecture\n",
    "        4. Authentication and authorization\n",
    "        5. AI service integration\n",
    "        Provide specific implementation strategies for robust and scalable backend systems.\"\"\",\n",
    "    )\n",
    "\n",
    "    # Create Quality Assurance agent\n",
    "    qa_engineer = AssistantAgent(\n",
    "        name=\"QA_Engineer\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0.2,  # More deterministic for finding issues\n",
    "            \"max_tokens\": 512,\n",
    "        },\n",
    "        system_message=\"\"\"You are the Quality Assurance Engineer. Your role is to review outputs of other agents and provide constructive feedback.\n",
    "        Focus on:\n",
    "        1. Identifying potential issues\n",
    "        2. Testing strategies\n",
    "        3. Edge cases\n",
    "        4. User experience evaluation\n",
    "        5. Performance considerations\n",
    "        Provide specific feedback to improve functionality, reliability, and usability.\"\"\",\n",
    "    )\n",
    "\n",
    "    # Return all agents in the desired speaking order\n",
    "    return [\n",
    "        founder,\n",
    "        product_manager,\n",
    "        tech_lead,\n",
    "        ui_ux_designer,\n",
    "        frontend_developer,\n",
    "        backend_developer,\n",
    "        qa_engineer,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Define function to run the startup team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_startup_team(task: str, max_round: int = 10):\n",
    "    \"\"\"Run the AI startup team with the given task.\"\"\"\n",
    "    try:\n",
    "        # Load Azure OpenAI configuration\n",
    "        logger.info(\"Loading configuration...\")\n",
    "        config_list = load_config()\n",
    "\n",
    "        # Create all agents for the team\n",
    "        logger.info(\"Creating AI startup team...\")\n",
    "        agents = create_agents(config_list)\n",
    "\n",
    "        # Create group chat to facilitate conversation between agents\n",
    "        groupchat = GroupChat(\n",
    "            agents=agents,\n",
    "            messages=[],\n",
    "            max_round=max_round,  # Maximum conversation rounds\n",
    "            speaker_selection_method=\"auto\",  # AutoGen decides which agent speaks next\n",
    "        )\n",
    "\n",
    "        # Create manager to coordinate the group chat\n",
    "        manager = GroupChatManager(\n",
    "            groupchat=groupchat, llm_config={\"config_list\": config_list}\n",
    "        )\n",
    "\n",
    "        # Start the conversation with the specified task\n",
    "        logger.info(\"Starting AI startup team conversation...\")\n",
    "        agents[0].initiate_chat(\n",
    "            manager,\n",
    "            message=task,\n",
    "        )\n",
    "\n",
    "        logger.info(\"AI startup team conversation completed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running AI startup team: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Define example task and start the conversation (Demo only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an AI product task for the team to work on\n",
    "task = \"\"\"\n",
    "We want to build an AI-powered productivity tool that:\n",
    "1. Automatically organizes and summarizes emails, messages, and documents\n",
    "2. Generates actionable to-do lists from communications\n",
    "3. Prioritizes tasks based on urgency and importance\n",
    "4. Integrates with common productivity tools (Gmail, Slack, MS Office)\n",
    "5. Provides a simple and intuitive interface for users\n",
    "\n",
    "Let's collaborate to define, design, and plan implementation for this product.\n",
    "\n",
    "For this demo, I'd like each team member to share ONLY their high-level thoughts based on their expertise.\n",
    "\"\"\"\n",
    "\n",
    "# Run the AI startup team with this task\n",
    "run_startup_team(task, max_round=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è 5. More Examples and Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö More Examples\n",
    "\n",
    "- [Data Analysis Agents](Examples/data_analyst_agent.py)\n",
    "- [Tutorial Lab Agent](Examples/tutorial_lab_agent.py)\n",
    "- [Architecture Design Agents](Examples/architecture_design_agent/README.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîó Resources\n",
    "\n",
    "- [AutoGen GitHub](https://github.com/microsoft/autogen)\n",
    "- [Official Docs](https://microsoft.github.io/autogen/stable/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
